<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Spring]]></title><description><![CDATA[Level up your Java code and explore what Spring can do for you.]]></description><link>https://spring.io</link><generator>GatsbyJS</generator><lastBuildDate>Thu, 16 Oct 2025 00:36:24 GMT</lastBuildDate><item><title><![CDATA[Spring Cloud Gateway 4.3.2, 4.2.5, 4.1.12, and 3.1.12 are now available]]></title><link>https://spring.io/blog/2025/10/15/spring-cloud-gateway-4</link><guid isPermaLink="true">https://spring.io/blog/2025/10/15/spring-cloud-gateway-4</guid><dc:creator><![CDATA[ryanjbaxter]]></dc:creator><pubDate>Wed, 15 Oct 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;On behalf of the Spring Cloud and everyone who has contributed, I am pleased to announce that Spring Cloud Gateway 4.3.2, 4.2.5, 4.1.12, and 3.1.12 are out! In all cases, the releases are mostly composed of bug fixes, dependency upgrades.&lt;/p&gt;
&lt;p&gt;Importantly, these releases address &lt;a href=&quot;https://spring.io/security/cve-2025-41253&quot;&gt;CVE-2025-41253&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Commercial customers will be able to update to Spring Cloud Gateway 4.1.12, and 3.1.12.
These commercial versions are available now on the Spring commercial artifact repository and can be accessed with a &lt;a href=&quot;https://spring.vmware.com&quot;&gt;Spring Enterprise Subscription&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Introducing Share Consumer Support (Kafka Queues) in Spring for Apache Kafka]]></title><link>https://spring.io/blog/2025/10/14/introducing-spring-kafka-share-consumer</link><guid isPermaLink="true">https://spring.io/blog/2025/10/14/introducing-spring-kafka-share-consumer</guid><dc:creator><![CDATA[sobychacko]]></dc:creator><pubDate>Tue, 14 Oct 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Continuing our &lt;a href=&quot;https://spring.io/blog/2025/09/02/road_to_ga_introduction&quot;&gt;Road to GA series&lt;/a&gt;, this week we&apos;re exploring Share Groups in Apache Kafka 4.0.0 and their integration in Spring for Apache Kafka 4.0.0 - a feature that fundamentally expands how we can consume messages from Kafka topics.&lt;/p&gt;
&lt;p&gt;When we first start working with Kafka, the mental model is straightforward: topics hold messages, consumers read them, and processing happens in order within partitions.
This partition-based model has served countless applications well, providing ordered processing with strong guarantees.
However, certain use cases involve creating topics with hundreds of partitions primarily to achieve higher parallelism rather than for any ordering requirement.
The relationship between partition count and consumer parallelism works perfectly when we need the ordering guarantees, but it becomes a constraint when we&apos;re processing independent events that don&apos;t require sequence preservation.&lt;/p&gt;
&lt;p&gt;Apache Kafka 4.0.0 introduces &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-932%3A+Queues+for+Kafka&quot;&gt;Share Groups (also known as &quot;Kafka Queues&quot;)&lt;/a&gt; as a complementary consumption model.
This addition doesn&apos;t replace traditional consumer groups but offers an alternative for scenarios where record-level distribution makes more sense than partition-level assignment.
Spring for Apache Kafka 4.0.0 brings full support for Share Groups, and in this post we&apos;ll explore how they work and when they fit our application needs.&lt;/p&gt;
&lt;p&gt;Note that Share Groups are currently in preview status in Kafka 4.1.0 and are expected to reach production-ready status in Kafka 4.2.0.&lt;/p&gt;
&lt;h2 id=&quot;two-models-for-different-needs&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#two-models-for-different-needs&quot; aria-label=&quot;two models for different needs permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Two Models for Different Needs&lt;/h2&gt;
&lt;p&gt;Traditional consumer groups assign entire partitions to consumers.
Each partition belongs to exactly one consumer in the group at any given time, which gives us ordered processing within that partition.&lt;/p&gt;
&lt;p&gt;Share Groups take a different approach by distributing individual records rather than entire partitions.
The broker coordinates record distribution across available consumers in the share group, allowing any consumer to receive any record regardless of which partition it came from.&lt;/p&gt;
&lt;p&gt;The key tradeoff: traditional consumer groups provide ordering guarantees through partition assignment, while Share Groups provide scaling flexibility through record-level distribution.&lt;/p&gt;
&lt;h2 id=&quot;when-to-use-share-groups&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#when-to-use-share-groups&quot; aria-label=&quot;when to use share groups permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;When to Use Share Groups&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Choose Share Groups when:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Processing high volumes of independent events where throughput matters more than sequence. Examples include image processing pipelines, notification services, and job coordination systems where each task stands alone.&lt;/li&gt;
&lt;li&gt;Workloads have variable demand patterns that fluctuate throughout the day or follow seasonal patterns. Share Groups let you scale consumers dynamically without provisioning hundreds of partitions for peak capacity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Continue using traditional consumer groups when:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sequence matters. If you&apos;re processing event streams where order is important (user sessions, financial transactions, state transitions), partition assignment with its ordering guarantees is the right model.&lt;/li&gt;
&lt;li&gt;Building stateful processing that maintains aggregations or windows. These scenarios need the partition affinity that traditional consumer groups provide.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;how-share-groups-work&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#how-share-groups-work&quot; aria-label=&quot;how share groups work permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How Share Groups Work&lt;/h2&gt;
&lt;p&gt;Let&apos;s look at the mechanics of Share Groups briefly to understand what changes under the hood.&lt;/p&gt;
&lt;p&gt;When we create a consumer in a share group, it connects to the broker and requests records.
The broker maintains coordination through a component called the Share Coordinator, which tracks which records have been assigned to which consumers.
When a consumer requests records, the broker selects unassigned records from the topic&apos;s partitions and delivers them to that consumer.
The records are now in &quot;acquired&quot; state - assigned to that specific consumer for processing.&lt;/p&gt;
&lt;p&gt;The acquired state comes with a time-based lock (default 30 seconds, configurable via &lt;code&gt;group.share.record.lock.duration.ms&lt;/code&gt;).
If the consumer doesn&apos;t acknowledge the record within this timeout, the broker automatically returns it to the available pool for another consumer to process.
This acquisition lock provides automatic failure recovery without requiring manual intervention when consumers crash or become unresponsive.&lt;/p&gt;
&lt;p&gt;The consumer processes the record and sends back an acknowledgment.
There are three possible acknowledgment types: &lt;code&gt;ACCEPT&lt;/code&gt; (processed successfully), &lt;code&gt;RELEASE&lt;/code&gt; (return to pool for retry), and &lt;code&gt;REJECT&lt;/code&gt; (mark as permanently failed).
Based on the acknowledgment, the broker updates the record&apos;s state and moves on.&lt;/p&gt;
&lt;p&gt;This coordination happens at the broker level, which is different from how traditional consumer groups work where consumers directly track their offsets.&lt;/p&gt;
&lt;p&gt;The broker also provides built-in retry semantics.
Each time a record is delivered to a consumer, the broker increments an internal delivery count.
By default, after 5 delivery attempts (configurable via &lt;code&gt;group.share.delivery.attempt.limit&lt;/code&gt;), the broker moves the record to archived state.
This gives us poison message protection without requiring application-level retry logic, though we can still implement our own retry strategies when we need more control.&lt;/p&gt;
&lt;h2 id=&quot;getting-started-with-share-groups&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#getting-started-with-share-groups&quot; aria-label=&quot;getting started with share groups permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started with Share Groups&lt;/h2&gt;
&lt;p&gt;The programming model for Share Groups in Spring for Apache Kafka stays close to what we already know.
We have two primary ways to set up share consumers: programmatic container creation and annotation-driven listeners with &lt;code&gt;@KafkaListener&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We start by configuring a &lt;code&gt;ShareConsumerFactory&lt;/code&gt; instead of a regular &lt;code&gt;ConsumerFactory&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Configuration
public class ShareConsumerConfig {

    @Bean
    public ShareConsumerFactory&amp;#x3C;String, String&gt; shareConsumerFactory() {
        Map&amp;#x3C;String, Object&gt; props = new HashMap&amp;#x3C;&gt;();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
                  StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,
                  StringDeserializer.class);
        return new DefaultShareConsumerFactory&amp;#x3C;&gt;(props);
    }

    @Bean
    public ShareKafkaListenerContainerFactory&amp;#x3C;String, String&gt;
            shareKafkaListenerContainerFactory(
                ShareConsumerFactory&amp;#x3C;String, String&gt; shareConsumerFactory) {
        return new ShareKafkaListenerContainerFactory&amp;#x3C;&gt;(shareConsumerFactory);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This configuration follows the same factory pattern we use for traditional consumers.
We&apos;re defining a factory that creates share consumers and a container factory that manages the listener lifecycle.
The Spring for Apache Kafka abstractions remain consistent across both consumption models.&lt;/p&gt;
&lt;h3 id=&quot;programmatic-container-creation&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#programmatic-container-creation&quot; aria-label=&quot;programmatic container creation permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Programmatic Container Creation&lt;/h3&gt;
&lt;p&gt;We can create a container programmatically and set up a message listener:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Bean
public ShareKafkaMessageListenerContainer&amp;#x3C;String, String&gt; imageProcessingContainer(
        ShareConsumerFactory&amp;#x3C;String, String&gt; shareConsumerFactory) {

    ContainerProperties containerProps = new ContainerProperties(&quot;image-processing&quot;);
    containerProps.setGroupId(&quot;image-processors&quot;);

    ShareKafkaMessageListenerContainer&amp;#x3C;String, String&gt; container =
        new ShareKafkaMessageListenerContainer&amp;#x3C;&gt;(shareConsumerFactory, containerProps);

    container.setupMessageListener(new MessageListener&amp;#x3C;String, String&gt;() {
        @Override
        public void onMessage(ConsumerRecord&amp;#x3C;String, String&gt; record) {
            imageService.process(record.value());
            // Implicit ACCEPT when method completes successfully
        }
    });

    return container;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This gives us fine-grained control over container creation and configuration.
We create a &lt;code&gt;ContainerProperties&lt;/code&gt; instance with the topic and group ID, instantiate the container with the factory and properties, and attach our message listener.&lt;/p&gt;
&lt;h3 id=&quot;annotation-driven-listeners&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#annotation-driven-listeners&quot; aria-label=&quot;annotation driven listeners permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Annotation-Driven Listeners&lt;/h3&gt;
&lt;p&gt;For most use cases, the annotation-driven approach with &lt;code&gt;@KafkaListener&lt;/code&gt; provides a cleaner programming model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@KafkaListener(
    topics = &quot;image-processing&quot;,
    groupId = &quot;image-processors&quot;,
    containerFactory = &quot;shareKafkaListenerContainerFactory&quot;
)
public void processImage(String imageUrl) {
    // Process the image
    imageService.process(imageUrl);
    // Implicit ACCEPT when method completes successfully
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;containerFactory&lt;/code&gt; attribute tells Spring to use our &lt;code&gt;ShareKafkaListenerContainerFactory&lt;/code&gt;, which creates a share consumer instead of a traditional consumer.
The &lt;code&gt;groupId&lt;/code&gt; now refers to a share group rather than a consumer group, but the annotation structure stays the same.&lt;/p&gt;
&lt;p&gt;When this method completes successfully, Spring for Apache Kafka automatically sends an &lt;code&gt;ACCEPT&lt;/code&gt; acknowledgment to the broker.
If an exception is thrown, it sends a &lt;code&gt;REJECT&lt;/code&gt;, which marks the record as permanently failed and prevents further delivery attempts.
This implicit acknowledgment mode works well for straightforward processing scenarios where success or failure maps cleanly to method completion or exception.
If you need transient failures to trigger retries (using &lt;code&gt;RELEASE&lt;/code&gt;), you&apos;ll want to use explicit acknowledgment mode for more fine-grained control.&lt;/p&gt;
&lt;h2 id=&quot;explicit-acknowledgment-for-fine-grained-control&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#explicit-acknowledgment-for-fine-grained-control&quot; aria-label=&quot;explicit acknowledgment for fine grained control permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Explicit Acknowledgment for Fine-Grained Control&lt;/h2&gt;
&lt;p&gt;Sometimes we need more control over how records are acknowledged.
We might want to explicitly reject poison messages that we know are invalid, or we might need to acknowledge at specific points in our processing logic rather than at method completion.&lt;/p&gt;
&lt;p&gt;We can enable explicit acknowledgment at different levels.
The most common approach is configuring it at the factory level:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Bean
public ShareConsumerFactory&amp;#x3C;String, String&gt; explicitShareConsumerFactory() {
	Map&amp;#x3C;String, Object&gt; props = new HashMap&amp;#x3C;&gt;();
	props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);
	props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
	props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
	props.put(ConsumerConfig.SHARE_ACKNOWLEDGEMENT_MODE_CONFIG, &quot;explicit&quot;);
	return new DefaultShareConsumerFactory&amp;#x3C;&gt;(props);
}

@Bean
public ShareKafkaListenerContainerFactory&amp;#x3C;String, String&gt; explicitShareKafkaListenerContainerFactory(
		ShareConsumerFactory&amp;#x3C;String, String&gt; explicitShareConsumerFactory) {
	// The factory will detect the explicit acknowledgment mode from the consumer factory configuration
	return new ShareKafkaListenerContainerFactory&amp;#x3C;&gt;(explicitShareConsumerFactory);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With explicit acknowledgment enabled, our listener method receives a &lt;code&gt;ShareAcknowledgment&lt;/code&gt; parameter that gives us direct control:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@KafkaListener(
    topics = &quot;payment-processing&quot;,
    groupId = &quot;payment-processors&quot;,
    containerFactory = &quot;shareKafkaListenerContainerFactory&quot;
)
public void processPayment(PaymentEvent event,
                          ShareAcknowledgment acknowledgment) {
    try {
        if (!isValid(event)) {
            // Permanently reject invalid events
            acknowledgment.reject();
            return;
        }

        paymentService.process(event);
        acknowledgment.accept();

    } catch (TransientException e) {
        // Release for retry with another consumer
        acknowledgment.release();
    } catch (PermanentException e) {
        // Don&apos;t retry unrecoverable errors
        acknowledgment.reject();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The three acknowledgment types give us precise control over record outcomes.
Calling &lt;code&gt;accept()&lt;/code&gt; tells the broker the record was processed successfully and can be archived.
Calling &lt;code&gt;release()&lt;/code&gt; returns the record to the pool for another consumer to process, useful for transient failures like temporary network issues or resource unavailability.
Calling &lt;code&gt;reject()&lt;/code&gt; marks the record as permanently failed and prevents further delivery attempts.&lt;/p&gt;
&lt;p&gt;One important constraint in explicit acknowledgment mode: the consumer cannot poll for new records until all previously delivered records have been acknowledged.
This prevents overwhelming the consumer with unprocessed records, but it means we must ensure every record receives an acknowledgment (accept, release, or reject) to avoid blocking the consumer thread.
Spring for Apache Kafka helps with debugging by logging warnings after 30 seconds (configurable via &lt;code&gt;shareAcknowledgmentTimeout&lt;/code&gt;) when records remain unacknowledged.&lt;/p&gt;
&lt;p&gt;Remember that each &lt;code&gt;release()&lt;/code&gt; increments the broker&apos;s internal delivery count, so the broker will eventually archive the record after reaching the configured limit, even if consumers keep calling &lt;code&gt;release()&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;scaling-with-concurrency&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#scaling-with-concurrency&quot; aria-label=&quot;scaling with concurrency permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Scaling with Concurrency&lt;/h2&gt;
&lt;p&gt;Traditional Kafka consumers process records sequentially - each consumer instance polls for records and processes them one at a time from its assigned partitions.
When we need more parallelism, we typically add more consumer instances, which often means more application instances or processes.&lt;/p&gt;
&lt;p&gt;Share Groups enable a different scaling approach because record-level distribution removes the partition assignment constraint.
Spring for Apache Kafka takes advantage of this by adding concurrency support directly to &lt;code&gt;ShareKafkaMessageListenerContainer&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We can configure multiple consumer threads within a single container:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Bean
public ShareKafkaListenerContainerFactory&amp;#x3C;String, String&gt;
        shareKafkaListenerContainerFactory(
            ShareConsumerFactory&amp;#x3C;String, String&gt; shareConsumerFactory) {
    ShareKafkaListenerContainerFactory&amp;#x3C;String, String&gt; factory =
        new ShareKafkaListenerContainerFactory&amp;#x3C;&gt;(shareConsumerFactory);
    factory.setConcurrency(10); // 10 concurrent consumer threads
    return factory;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a container with 10 threads, each running its own share consumer polling loop.
All 10 threads pull records from the same share group and process them concurrently within the same JVM.
If we&apos;re running this across 5 application instances, that&apos;s 50 concurrent consumers working through the record stream.&lt;/p&gt;
&lt;p&gt;This concurrency model gives us flexibility in how we scale.
We can scale vertically by increasing concurrency (more threads per instance) or horizontally by adding more instances, or both.
For workloads with variable demand, we can adjust concurrency settings or instance counts without changing topic configuration or worrying about partition rebalancing.&lt;/p&gt;
&lt;h2 id=&quot;current-status-and-compatibility&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#current-status-and-compatibility&quot; aria-label=&quot;current status and compatibility permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Current Status and Compatibility&lt;/h2&gt;
&lt;p&gt;Share Groups were introduced as early access in Kafka 4.0.0, moved to preview in Kafka 4.1.0, and are expected to reach production-ready status in Kafka 4.2.0.
Spring for Apache Kafka 4.0.0 (shipping with Spring Boot 4.0.0) provides support for Share Groups as implemented in Kafka 4.1.0 version.&lt;/p&gt;
&lt;p&gt;There&apos;s an important compatibility consideration: Kafka 4.0.0 and 4.1.0 are not compatible for Share Groups.
The protocol evolved between these versions, so clients and brokers need to be on the same minor version when using Share Groups.
This matters particularly in environments where brokers and client libraries might upgrade at different times.&lt;/p&gt;
&lt;h2 id=&quot;wrapping-up&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#wrapping-up&quot; aria-label=&quot;wrapping up permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;Share Groups expand Kafka&apos;s consumption models by adding record-level distribution as an alternative to partition-level assignment.
Both models serve important purposes - traditional consumer groups with their ordering guarantees remain essential for stateful processing and event sequencing, while Share Groups offer advantages for high-throughput processing of independent events.&lt;/p&gt;
&lt;p&gt;The key is matching the consumption model to our application requirements.
When sequence matters, partition assignment gives us the guarantees we need.
When throughput and scaling flexibility matter more than order, record-level distribution can simplify our architecture and resource management.&lt;/p&gt;
&lt;p&gt;The Spring for Apache Kafka implementation supports &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-932%3A+Queues+for+Kafka&quot;&gt;KIP-932&lt;/a&gt; and adds Spring-specific enhancements.
The &lt;code&gt;@KafkaListener&lt;/code&gt; integration maintains consistency with the programming model we use for traditional consumers.
The built-in concurrency support provides options for scaling within a single application instance.
Features like timeout detection and graceful shutdown help production deployments handle operational concerns.&lt;/p&gt;
&lt;p&gt;Spring for Apache Kafka 4.0.0 makes working with Share Groups feel natural by maintaining consistency with the existing &lt;code&gt;@KafkaListener&lt;/code&gt; model.
We can adopt Share Groups incrementally, using them for specific use cases while continuing to use traditional consumer groups for others.
The two models coexist within the same Spring for Apache Kafka application without conflict.&lt;/p&gt;
&lt;p&gt;As Share Groups move toward production readiness in Kafka 4.2.0, it&apos;s worth evaluating whether they fit any of our current or planned use cases.
If we&apos;ve been provisioning high partition counts primarily for parallelism rather than ordering, or if we&apos;re dealing with variable workloads that make capacity planning difficult, Share Groups might offer a simpler approach.&lt;/p&gt;
&lt;p&gt;For more details on Share Groups in Spring for Apache Kafka, check out the &lt;a href=&quot;https://docs.spring.io/spring-kafka/reference/4.0-SNAPSHOT/kafka/kafka-queues.html&quot;&gt;reference documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We welcome your feedback as you explore Share Groups in your applications.
If you encounter issues or have suggestions for improvement, please open an issue on the &lt;a href=&quot;https://github.com/spring-projects/spring-kafka/issues&quot;&gt;Spring for Apache Kafka GitHub repository&lt;/a&gt;.
Your input helps us improve the framework as we move toward the GA release and beyond.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Spring Session Hazelcast: Now Led by Hazelcast Team]]></title><link>https://spring.io/blog/2025/10/14/spring-session-hazelcast-new-leadership</link><guid isPermaLink="true">https://spring.io/blog/2025/10/14/spring-session-hazelcast-new-leadership</guid><dc:creator><![CDATA[rwinch]]></dc:creator><pubDate>Tue, 14 Oct 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;It gives me great pleasure to announce that the &lt;a href=&quot;https://hazelcast.com/blog/spring-session-hazelcast&quot;&gt;Spring Session Hazelcast project will now be led by the Hazelcast Team&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;NOTE: This announcement is in alignment with our announcement &lt;a href=&quot;https://spring.io/blog/2025/10/14/spring-session-mongodb-new-leadership&quot;&gt;Spring Session MongoDB: Now Led by MongoDB Team&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For ten years Spring Session has provided the infrastructure for transparently replacing session stores in a vendor independent manner.
With that infrastructure in place, it is just a matter of implementing &lt;a href=&quot;https://docs.spring.io/spring-session/reference/api.html#api-sessionrepository&quot;&gt;SessionRepository&lt;/a&gt; javadoc in order to support storing session information in a new datastore.&lt;/p&gt;
&lt;p&gt;I cannot think of a team who has more Hazelcast experience than the Hazelcast team themselves and so it gives me great pleasure to announce the Hazelcast team will be leading the next generation of Spring Session Hazelcast!
To best enable this transition, the next generation of releases will be in a new GitHub repository and have new Maven coordinates.
Support for existing generations of Spring Session Hazelcast will continue to be maintained by the Spring Session team as described by the &lt;a href=&quot;https://spring.io/support-policy&quot;&gt;Spring Support Policy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For more information, please see the &lt;a href=&quot;https://hazelcast.com/blog/spring-session-hazelcast&quot;&gt;announcement from the Hazelcast team&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Spring Session MongoDB: Now Led by MongoDB Team]]></title><link>https://spring.io/blog/2025/10/14/spring-session-mongodb-new-leadership</link><guid isPermaLink="true">https://spring.io/blog/2025/10/14/spring-session-mongodb-new-leadership</guid><dc:creator><![CDATA[rwinch]]></dc:creator><pubDate>Tue, 14 Oct 2025 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;It gives me great pleasure to announce that the &lt;a href=&quot;https://www.mongodb.com/company/blog/product-release-announcements/spring-session-mongodb-moves-to-new-open-source-home&quot;&gt;Spring Session MongoDB project will now be led by the MongoDB Team&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;NOTE: This announcement is in alignment with our announcement &lt;a href=&quot;https://spring.io/blog/2025/10/14/spring-session-hazelcast-new-leadership&quot;&gt;Spring Session Hazelcast: Now Led by Hazelcast Team&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For ten years Spring Session has provided the infrastructure for transparently replacing session stores in a vendor independent manner.
With that infrastructure in place, it is just a matter of implementing &lt;a href=&quot;https://docs.spring.io/spring-session/reference/api.html#api-sessionrepository&quot;&gt;SessionRepository&lt;/a&gt; javadoc in order to support storing session information in a new datastore.&lt;/p&gt;
&lt;p&gt;I cannot think of a team who has more MongoDB experience than the MongoDB team themselves and so it gives me great pleasure to announce that the MongoDB team will be leading the next generation of Spring Session MongoDB!
To best enable this transition, the next generation of code will be hosted in a new GitHub repository and have new Maven coordinates, both available in November.
Support for existing generations of Spring Session MongoDB will continue to be maintained by the Spring Session team as described by the &lt;a href=&quot;https://spring.io/support-policy&quot;&gt;Spring Support Policy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For more information, please see the &lt;a href=&quot;https://www.mongodb.com/company/blog/product-release-announcements/spring-session-mongodb-moves-to-new-open-source-home&quot;&gt;announcement from the MongoDB team&lt;/a&gt;.&lt;/p&gt;</content:encoded></item></channel></rss>